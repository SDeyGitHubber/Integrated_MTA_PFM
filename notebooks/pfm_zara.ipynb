{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2eSdvKWv35fc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import time\n",
        "\n",
        "# Dataset Class\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib.widgets import Slider\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import gc\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PFM_TrajectoryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, file_path, history_len=8, prediction_len=12):\n",
        "        self.data, self.uses_scene_id = self.load_data(file_path)\n",
        "        self.history_len = history_len\n",
        "        self.prediction_len = prediction_len\n",
        "        self.valid_frames = self._get_valid_frames()\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        data = {}\n",
        "        uses_scene_id = False\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line_idx, line in enumerate(file):\n",
        "                parts = line.strip().split(',')\n",
        "                if len(parts) == 4:\n",
        "                    c1, agent, x, y = map(float, parts)\n",
        "                    agent = int(agent)\n",
        "\n",
        "                    # Detect format:\n",
        "                    # If c1 grows smoothly like 10,20,30 => Zara format\n",
        "                    # Else if c1 is same for many lines => scene ID format\n",
        "                    if line_idx == 0:\n",
        "                        first_val = c1\n",
        "                    if line_idx == 1 and c1 == first_val:\n",
        "                        uses_scene_id = True\n",
        "\n",
        "                    frame = int(c1) if not uses_scene_id else line_idx  # if Zara -> frame, else use line index as frame\n",
        "                    if frame not in data:\n",
        "                        data[frame] = {}\n",
        "                    data[frame][agent] = torch.tensor([x, y], dtype=torch.float32)\n",
        "\n",
        "        return data, uses_scene_id\n",
        "\n",
        "    def _get_valid_frames(self):\n",
        "        all_frames = sorted(self.data.keys())\n",
        "        valid_frames = []\n",
        "        for frame in all_frames:\n",
        "            history_start = frame - self.history_len + 1\n",
        "            future_end = frame + self.prediction_len\n",
        "            if history_start >= min(all_frames) and future_end <= max(all_frames):\n",
        "                valid_frames.append(frame)\n",
        "        return valid_frames\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame = self.valid_frames[idx]\n",
        "        agents = list(self.data[frame].keys())\n",
        "        num_agents = len(agents)\n",
        "\n",
        "        history = torch.zeros(num_agents, self.history_len, 2)\n",
        "        future = torch.zeros(num_agents, self.prediction_len, 2)\n",
        "        goals = torch.zeros(num_agents, 2)\n",
        "\n",
        "        # Build history & future\n",
        "        for i, agent in enumerate(agents):\n",
        "            for t in range(self.history_len):\n",
        "                hist_frame = frame - (self.history_len - 1 - t)\n",
        "                if hist_frame in self.data and agent in self.data[hist_frame]:\n",
        "                    history[i, t] = self.data[hist_frame][agent]\n",
        "            for t in range(self.prediction_len):\n",
        "                fut_frame = frame + t + 1\n",
        "                if fut_frame in self.data and agent in self.data[fut_frame]:\n",
        "                    future[i, t] = self.data[fut_frame][agent]\n",
        "\n",
        "            # goal = last non-zero future point\n",
        "            non_zero_mask = torch.any(future[i] != 0, dim=1)\n",
        "            if non_zero_mask.any():\n",
        "                last_valid_idx = torch.where(non_zero_mask)[0][-1]\n",
        "                goals[i] = future[i, last_valid_idx]\n",
        "            else:\n",
        "                goals[i] = self.data[frame][agent]\n",
        "\n",
        "        # Build neighbors\n",
        "        neighbors_list = []\n",
        "        for i, agent in enumerate(agents):\n",
        "            agent_neighbors = [self.data[frame][other] for other in self.data[frame] if other != agent]\n",
        "            if agent_neighbors:\n",
        "                neighbors_tensor = torch.stack(agent_neighbors)\n",
        "            else:\n",
        "                neighbors_tensor = torch.zeros(1, 2)\n",
        "            neighbors_list.append(neighbors_tensor)\n",
        "\n",
        "        max_neighbors = 12\n",
        "        padded_neighbors = torch.zeros(num_agents, max_neighbors, 2)\n",
        "        for i, neighbor_tensor in enumerate(neighbors_list):\n",
        "            if neighbor_tensor.shape[0] > 0:\n",
        "                ego_pos = history[i, -1].unsqueeze(0)\n",
        "                dists = torch.norm(neighbor_tensor - ego_pos, dim=1)\n",
        "                sorted_idx = torch.argsort(dists)\n",
        "                sorted_neighbors = neighbor_tensor[sorted_idx]\n",
        "                top_neighbors = sorted_neighbors[:max_neighbors]\n",
        "                padded_neighbors[i, :top_neighbors.shape[0]] = top_neighbors\n",
        "        neighbors = padded_neighbors\n",
        "\n",
        "        # Mask invalid agents\n",
        "        mask = torch.ones(history.shape[0], dtype=torch.bool)\n",
        "        for i in range(history.shape[0]):\n",
        "            if torch.all(history[i] == 0) or torch.all(future[i] == 0):\n",
        "                mask[i] = False\n",
        "        history = history[mask]\n",
        "        future = future[mask]\n",
        "        neighbors = neighbors[mask]\n",
        "        goals = goals[mask]\n",
        "\n",
        "        return history, future, neighbors, goals"
      ],
      "metadata": {
        "id": "NzmAAWg64ByT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for batches that include goal\"\"\"\n",
        "    max_agents = max(sample[0].shape[0] for sample in batch)\n",
        "    # history\n",
        "    max_neighbors = max(sample[2].shape[1] for sample in batch)  # neighbors\n",
        "    hist_len = batch[0][0].shape[1]\n",
        "    fut_len = batch[0][1].shape[1]\n",
        "\n",
        "    padded_histories = []\n",
        "    padded_futures = []\n",
        "    padded_neighbors = []\n",
        "    padded_goals = []\n",
        "\n",
        "    for sample in batch:\n",
        "        history, future, neighbors, goal = sample\n",
        "        A, H, D = history.shape\n",
        "        N = neighbors.shape[1]\n",
        "\n",
        "        padded_hist = torch.zeros(max_agents, hist_len, D)\n",
        "        padded_fut = torch.zeros(max_agents, fut_len, D)\n",
        "        padded_neigh = torch.zeros(max_agents, max_neighbors, D)\n",
        "        padded_goal = torch.zeros(max_agents, D)\n",
        "\n",
        "        padded_hist[:A] = history\n",
        "        padded_fut[:A] = future\n",
        "        padded_neigh[:A, :N] = neighbors\n",
        "        padded_goal[:A] = goal\n",
        "\n",
        "        padded_histories.append(padded_hist)\n",
        "        padded_futures.append(padded_fut)\n",
        "        padded_neighbors.append(padded_neigh)\n",
        "        padded_goals.append(padded_goal)\n",
        "\n",
        "    return (\n",
        "        torch.stack(padded_histories),   # [B, A, hist_len, D]\n",
        "        torch.stack(padded_futures),     # [B, A, fut_len, D]\n",
        "        torch.stack(padded_neighbors),   # [B, A, max_neighbors, D]\n",
        "        torch.stack(padded_goals)        # [B, A, D]\n",
        "    )\n",
        "\n",
        "# FIXED: Added goals to test data (4th element in each tuple)\n",
        "test_batch = [\n",
        "    (torch.rand(3, 8, 2), torch.rand(3, 12, 2), torch.rand(3, 5, 2), torch.rand(3, 2)),  # 3 agents with goals\n",
        "    (torch.rand(2, 8, 2), torch.rand(2, 12, 2), torch.rand(2, 3, 2), torch.rand(2, 2)),  # 2 agents with goals\n",
        "    (torch.rand(4, 8, 2), torch.rand(4, 12, 2), torch.rand(4, 6, 2), torch.rand(4, 2))   # 4 agents with goals\n",
        "]\n",
        "\n",
        "# Now this should work correctly\n",
        "hist, fut, neigh, goals = collate_fn(test_batch)  # Note: also need to unpack goals here\n",
        "print(f\"History shape: {hist.shape}\")     # Will be [3, 4, 8, 2]\n",
        "print(f\"Future shape: {fut.shape}\")       # Will be [3, 4, 12, 2]\n",
        "print(f\"Neighbors shape: {neigh.shape}\")  # Will be [3, 4, 6, 2]\n",
        "print(f\"Goals shape: {goals.shape}\")      # Will be [3, 4, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rQc1fKu4B3a",
        "outputId": "5afb1147-27aa-4595-fa67-f74f4a6603d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "History shape: torch.Size([3, 4, 8, 2])\n",
            "Future shape: torch.Size([3, 4, 12, 2])\n",
            "Neighbors shape: torch.Size([3, 4, 6, 2])\n",
            "Goals shape: torch.Size([3, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_average_speed_from_file_ZARA(file_path, delimiter=None):\n",
        "    \"\"\"\n",
        "    Compute average speed across all agents from trajectory data in file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file containing data: frame agent x y\n",
        "        delimiter (str or None): delimiter for np.loadtxt (default None detects spaces).\n",
        "                                Use \",\" if your file is comma separated.\n",
        "\n",
        "    Returns:\n",
        "        float: average speed (units per frame step)\n",
        "    \"\"\"\n",
        "    # Load dataset: shape (N,4) --> frame, agent, x, y\n",
        "    data = np.loadtxt(file_path, delimiter=delimiter)\n",
        "\n",
        "    # Sort by agent then by frame to ensure proper ordering\n",
        "    data = data[np.lexsort((data[:,0], data[:,1]))]\n",
        "\n",
        "    total_distance = 0.0\n",
        "    total_transitions = 0\n",
        "\n",
        "    # Process each agent separately\n",
        "    for agent_id in np.unique(data[:,1]):\n",
        "        agent_data = data[data[:,1] == agent_id]\n",
        "\n",
        "        # Filter out zero positions (padded)\n",
        "        mask = ~((agent_data[:,2] == 0) & (agent_data[:,3] == 0))\n",
        "        agent_data = agent_data[mask]\n",
        "\n",
        "        if len(agent_data) < 2:\n",
        "            continue\n",
        "\n",
        "        frames = agent_data[:,0]\n",
        "        positions = agent_data[:, 2:4]\n",
        "\n",
        "        # Calculate Euclidean distances between consecutive positions\n",
        "        displacements = positions[1:] - positions[:-1]\n",
        "        distances = np.linalg.norm(displacements, axis=1)\n",
        "\n",
        "        # Calculate time differences (frame differences)\n",
        "        delta_times = frames[1:] - frames[:-1]\n",
        "\n",
        "        # Ignore zero or negative time intervals (avoid division issues)\n",
        "        valid_mask = delta_times > 0\n",
        "\n",
        "        total_distance += distances[valid_mask].sum()\n",
        "        total_transitions += delta_times[valid_mask].sum()  # total time elapsed\n",
        "\n",
        "    if total_transitions > 0:\n",
        "        avg_speed = total_distance / total_transitions\n",
        "    else:\n",
        "        avg_speed = 0.0\n",
        "\n",
        "    return avg_speed\n",
        "\n",
        "file_path = \"/content/crowds_zara02_test.txt\"\n",
        "average_speed = compute_average_speed_from_file_ZARA(file_path)\n",
        "print(f\"Average speed: {average_speed:.4f} units per frame\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW78Udcs4IHY",
        "outputId": "f5d77982-e6a0-41e3-b8d3-316fecaf2748"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average speed: 0.0278 units per frame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_speed(trajectory):\n",
        "    \"\"\"Calculate average speed from trajectory tensor [B, A, T, 2]\"\"\"\n",
        "    diffs = trajectory[:, :, 1:, :] - trajectory[:, :, :-1, :]  # Frame-to-frame differences\n",
        "    speeds = torch.norm(diffs, dim=-1)  # [B, A, T-1]\n",
        "    valid_mask = speeds > 0\n",
        "    if valid_mask.sum() > 0:\n",
        "        avg_speed = speeds[valid_mask].mean()\n",
        "    else:\n",
        "        avg_speed = torch.tensor(0.0)\n",
        "    return avg_speed\n",
        "\n",
        "def check_speed_violations(predictions, history, min_speed, max_speed):\n",
        "    \"\"\"Count speed violations in predicted trajectories\"\"\"\n",
        "    # Get last history position\n",
        "    last_pos = history[:, :, -1:, :]  # [B, A, 1, 2]\n",
        "\n",
        "    # Combine last history with predictions for speed calculation\n",
        "    full_traj = torch.cat([last_pos, predictions], dim=2)  # [B, A, T+1, 2]\n",
        "\n",
        "    # Calculate speeds\n",
        "    diffs = full_traj[:, :, 1:, :] - full_traj[:, :, :-1, :]\n",
        "    speeds = torch.norm(diffs, dim=-1)  # [B, A, T]\n",
        "\n",
        "    # Count violations\n",
        "    violations = ((speeds < min_speed) | (speeds > max_speed)).sum().item()\n",
        "    return violations"
      ],
      "metadata": {
        "id": "CxW9rW5_4IJt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class PotentialField(nn.Module):\n",
        "    def __init__(self, goal, num_agents=1000, k_init=1.0, repulsion_radius=0.5):\n",
        "        super().__init__()\n",
        "        self.register_buffer('goal', torch.tensor(goal, dtype=torch.float32))\n",
        "        self.repulsion_radius = repulsion_radius\n",
        "        self.coeff_embedding = nn.Embedding(num_agents, 3)\n",
        "        self.coeff_embedding.weight.data.fill_(k_init)\n",
        "\n",
        "    def forward(self, pos, predicted, neighbors, goal, coeffs):\n",
        "        k_att1 = coeffs[..., 0:1]\n",
        "        k_att2 = coeffs[..., 1:2]\n",
        "        k_rep = coeffs[..., 2:3]\n",
        "\n",
        "        F_goal = k_att1 * (goal - pos)\n",
        "        F_pred = k_att2 * (predicted[:, :, 0, :] - pos)\n",
        "\n",
        "        diffs = pos.unsqueeze(2) - neighbors\n",
        "        dists = torch.norm(diffs, dim=-1, keepdim=True) + 1e-6\n",
        "        mask = (dists < self.repulsion_radius).float()\n",
        "\n",
        "        F_rep = (k_rep.unsqueeze(2) * diffs / dists.pow(2) * mask).sum(dim=2)\n",
        "\n",
        "        total_force = F_goal + F_pred + F_rep\n",
        "\n",
        "        return total_force, coeffs\n",
        "\n",
        "\n",
        "class CheckpointedIntegratedMTAPFMModel(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_size=64, num_layers=2,\n",
        "                 goal=(4.2,4.2), target_avg_speed=0.027,\n",
        "                 speed_tolerance=0.15, num_agents=1000):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.input_embed = nn.Linear(input_size, hidden_size)\n",
        "        self.encoder = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.decoder = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # If postprocess is unnecessary, replace with identity\n",
        "        # self.postprocess = nn.Identity()\n",
        "        self.postprocess = nn.Linear(input_size, input_size)\n",
        "\n",
        "\n",
        "        self.output = nn.Linear(hidden_size, input_size)\n",
        "        self.pfm = PotentialField(goal=goal, num_agents=num_agents)\n",
        "\n",
        "        if target_avg_speed is None:\n",
        "            raise ValueError(\"target_avg_speed must be computed from dataset and passed here.\")\n",
        "\n",
        "        self.target_avg_speed = target_avg_speed\n",
        "        self.speed_tolerance = speed_tolerance\n",
        "        self.min_speed = self.target_avg_speed * (1 - self.speed_tolerance)\n",
        "        self.max_speed = self.target_avg_speed * (1 + self.speed_tolerance)\n",
        "\n",
        "    def apply_speed_constraints(self, predictions, last_positions):\n",
        "        B, A, T, D = predictions.shape\n",
        "        constrained_preds = predictions.clone()\n",
        "        current_pos = last_positions.clone()\n",
        "        for t in range(T):\n",
        "            displacement = predictions[:, :, t] - current_pos\n",
        "            speeds = torch.norm(displacement, dim=-1, keepdim=True)\n",
        "            non_zero_mask = speeds > 0\n",
        "            clipped_speeds = torch.clamp(speeds, self.min_speed, self.max_speed)\n",
        "            final_speeds = torch.where(non_zero_mask, clipped_speeds, speeds)\n",
        "            direction = displacement / (speeds + 1e-8)\n",
        "            clipped_displacement = direction * final_speeds\n",
        "            constrained_preds[:, :, t] = current_pos + clipped_displacement\n",
        "            current_pos = constrained_preds[:, :, t].clone()\n",
        "        return constrained_preds\n",
        "\n",
        "    def forward_encoder(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def forward_decoder_step(self, input_step, hx):\n",
        "        return self.decoder(input_step, hx)\n",
        "\n",
        "    def forward(self, history, neighbors, goal):\n",
        "        B, A, H, D = history.shape\n",
        "        device = history.device\n",
        "        agent_ids = torch.arange(A).repeat(B, 1).to(device)\n",
        "\n",
        "        hist_flat = history.reshape(B * A, H, D)\n",
        "        hist_embedded = self.input_embed(hist_flat)\n",
        "        # print('history',history)\n",
        "        # print('neighbours',neighbors)\n",
        "        # print('goal', goal)\n",
        "\n",
        "        # Gradient checkpoint on encoder\n",
        "        _, (h_n, c_n) = checkpoint.checkpoint(self.forward_encoder, hist_embedded)\n",
        "\n",
        "        pred_flat = torch.zeros(B * A, 12, D, device=device)\n",
        "\n",
        "        h_n = h_n[-1].unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
        "        c_n = c_n[-1].unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
        "        hx = (h_n, c_n)\n",
        "\n",
        "        for t in range(12):\n",
        "            current_pred = pred_flat[:, t:t+1].clone()\n",
        "            pred_embedded = self.input_embed(current_pred)\n",
        "            out, hx = checkpoint.checkpoint(self.forward_decoder_step, pred_embedded, hx)\n",
        "            step_output = self.output(out.squeeze(1))\n",
        "            pred_flat[:, t] = self.postprocess(step_output)\n",
        "\n",
        "        predictions = pred_flat.view(B, A, 12, D)\n",
        "        adjusted_preds = torch.zeros_like(predictions)\n",
        "        current_pos = history[:, :, -1, :].clone()\n",
        "        coeff_list = []\n",
        "\n",
        "        coeffs = self.pfm.coeff_embedding(agent_ids)\n",
        "\n",
        "        for t in range(12):\n",
        "            pred_slice = predictions[:, :, t:t+1].clone()\n",
        "            forces, coeff_step = self.pfm(current_pos, pred_slice, neighbors.clone(), goal, coeffs)\n",
        "            if t == 0:\n",
        "                adjusted_preds[:, :, t] = current_pos + forces\n",
        "            else:\n",
        "                adjusted_preds[:, :, t] = adjusted_preds[:, :, t-1] + forces\n",
        "            coeff_list.append(coeff_step)\n",
        "            current_pos = adjusted_preds[:, :, t].clone()\n",
        "\n",
        "        last_known_pos = history[:, :, -1, :]\n",
        "\n",
        "        constrained_preds = self.apply_speed_constraints(adjusted_preds, last_known_pos)\n",
        "        # print(constrained_preds)\n",
        "        coeff_stack = torch.stack(coeff_list, dim=0)\n",
        "        coeff_mean = coeff_stack.mean()\n",
        "        coeff_var = coeff_stack.var(unbiased=False)\n",
        "\n",
        "        return constrained_preds, coeff_mean, coeff_var"
      ],
      "metadata": {
        "id": "z3yietT74VnY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define test dimensions\n",
        "batch_size = 32\n",
        "num_agents = 1000\n",
        "history_len = 8\n",
        "num_neighbors = 10\n",
        "goal_dim = 2\n",
        "\n",
        "# Initialize the model\n",
        "model = CheckpointedIntegratedMTAPFMModel(input_size=2, hidden_size=64)\n",
        "\n",
        "# Generate random input tensors\n",
        "test_input = torch.rand(batch_size, num_agents, history_len, goal_dim)      # [B, A, H, 2]\n",
        "test_neighbors = torch.rand(batch_size, num_agents, num_neighbors, goal_dim)  # [B, A, N, 2]\n",
        "\n",
        "# Generate random goals for each agent\n",
        "test_goal = torch.rand(batch_size, num_agents, goal_dim)  # [B, A, 2]\n",
        "\n",
        "# Forward pass\n",
        "output, coeff_mean, coeff_var = model(test_input, test_neighbors, test_goal)\n",
        "\n",
        "# Output result shapes\n",
        "print(\"Output shape:\", output.shape)        # Expected: [32, 5, 12, 2]\n",
        "print(\"Coeff mean:\", coeff_mean.item())\n",
        "print(\"Coeff var:\", coeff_var.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9m_EbxsR4ZOK",
        "outputId": "285a53db-a3dd-49c0-b2bc-4edeab31db6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history tensor([[[[2.6057e-01, 1.4399e-02],\n",
            "          [7.6890e-01, 9.9851e-01],\n",
            "          [5.5962e-01, 8.5919e-01],\n",
            "          ...,\n",
            "          [5.4017e-01, 3.6295e-01],\n",
            "          [7.2765e-01, 2.7785e-02],\n",
            "          [7.7101e-02, 5.4937e-01]],\n",
            "\n",
            "         [[8.6097e-01, 9.6594e-02],\n",
            "          [5.4383e-01, 3.6959e-01],\n",
            "          [1.7857e-01, 2.1652e-01],\n",
            "          ...,\n",
            "          [5.9590e-02, 7.1777e-02],\n",
            "          [1.1094e-01, 2.4175e-01],\n",
            "          [5.1470e-01, 9.9765e-01]],\n",
            "\n",
            "         [[4.7902e-01, 4.5142e-01],\n",
            "          [8.7579e-01, 7.0143e-01],\n",
            "          [6.0260e-01, 2.4974e-01],\n",
            "          ...,\n",
            "          [9.2126e-01, 7.3852e-01],\n",
            "          [7.5591e-01, 4.8239e-02],\n",
            "          [5.1443e-01, 3.1856e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[9.8892e-02, 1.6657e-01],\n",
            "          [9.4136e-01, 7.1780e-01],\n",
            "          [4.6063e-01, 2.9086e-01],\n",
            "          ...,\n",
            "          [9.2423e-01, 6.7055e-01],\n",
            "          [1.4595e-01, 8.9663e-01],\n",
            "          [5.0335e-01, 6.7908e-01]],\n",
            "\n",
            "         [[9.5884e-01, 1.8369e-01],\n",
            "          [4.1645e-01, 9.9918e-01],\n",
            "          [8.5231e-01, 3.2738e-01],\n",
            "          ...,\n",
            "          [4.2000e-01, 4.9668e-01],\n",
            "          [3.2320e-01, 7.1153e-02],\n",
            "          [4.0689e-01, 9.8466e-01]],\n",
            "\n",
            "         [[1.0620e-01, 9.6305e-01],\n",
            "          [1.4802e-01, 2.6200e-02],\n",
            "          [6.8187e-01, 6.4466e-01],\n",
            "          ...,\n",
            "          [8.3823e-01, 8.3819e-01],\n",
            "          [8.1398e-01, 3.4004e-01],\n",
            "          [5.5361e-01, 5.3392e-01]]],\n",
            "\n",
            "\n",
            "        [[[8.4061e-01, 9.3786e-01],\n",
            "          [5.6328e-01, 2.3822e-01],\n",
            "          [2.2725e-01, 5.7148e-01],\n",
            "          ...,\n",
            "          [6.6693e-01, 5.6376e-01],\n",
            "          [9.5179e-01, 8.7801e-01],\n",
            "          [2.5769e-01, 6.8035e-01]],\n",
            "\n",
            "         [[5.9222e-01, 5.4434e-02],\n",
            "          [8.6009e-01, 7.7995e-01],\n",
            "          [6.9136e-01, 4.7199e-01],\n",
            "          ...,\n",
            "          [4.2006e-01, 7.7818e-01],\n",
            "          [8.4381e-01, 4.9891e-01],\n",
            "          [5.7474e-02, 5.2803e-01]],\n",
            "\n",
            "         [[9.4911e-01, 2.8460e-01],\n",
            "          [5.8126e-04, 3.8121e-01],\n",
            "          [3.4003e-01, 4.3767e-01],\n",
            "          ...,\n",
            "          [9.6295e-01, 8.6602e-01],\n",
            "          [5.9230e-01, 6.6562e-01],\n",
            "          [4.8421e-01, 9.1858e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[9.6057e-01, 2.3892e-01],\n",
            "          [8.1746e-02, 4.2020e-02],\n",
            "          [6.9526e-01, 4.2000e-01],\n",
            "          ...,\n",
            "          [3.2848e-01, 6.8327e-01],\n",
            "          [1.3154e-01, 9.9213e-01],\n",
            "          [6.5435e-01, 1.4190e-03]],\n",
            "\n",
            "         [[6.5130e-01, 3.6333e-01],\n",
            "          [2.6485e-01, 3.0377e-01],\n",
            "          [6.9316e-01, 6.0702e-01],\n",
            "          ...,\n",
            "          [2.4315e-01, 9.9184e-01],\n",
            "          [3.6221e-01, 1.5162e-01],\n",
            "          [4.4807e-01, 7.4953e-01]],\n",
            "\n",
            "         [[8.4928e-02, 7.1842e-01],\n",
            "          [7.5523e-01, 4.5356e-01],\n",
            "          [1.9235e-01, 5.8679e-01],\n",
            "          ...,\n",
            "          [8.6779e-01, 7.2824e-01],\n",
            "          [2.2161e-01, 8.4713e-01],\n",
            "          [4.7218e-01, 7.6057e-01]]],\n",
            "\n",
            "\n",
            "        [[[1.6149e-01, 5.3580e-01],\n",
            "          [9.0728e-01, 8.1155e-01],\n",
            "          [4.6604e-01, 7.8937e-01],\n",
            "          ...,\n",
            "          [3.9934e-01, 7.2797e-01],\n",
            "          [2.7897e-01, 5.6794e-01],\n",
            "          [6.9016e-01, 8.7176e-01]],\n",
            "\n",
            "         [[3.1661e-01, 8.8459e-01],\n",
            "          [6.7174e-01, 2.4726e-01],\n",
            "          [4.4445e-01, 7.8699e-01],\n",
            "          ...,\n",
            "          [8.5715e-01, 6.2511e-01],\n",
            "          [7.5003e-01, 1.6277e-01],\n",
            "          [3.0351e-01, 7.6155e-01]],\n",
            "\n",
            "         [[7.7375e-01, 5.8282e-01],\n",
            "          [1.8562e-01, 6.7635e-01],\n",
            "          [4.0625e-01, 7.2847e-01],\n",
            "          ...,\n",
            "          [8.5977e-01, 7.7653e-01],\n",
            "          [3.5277e-01, 6.3939e-01],\n",
            "          [1.8480e-01, 1.1493e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[4.6188e-01, 2.8032e-01],\n",
            "          [2.2317e-01, 5.3758e-01],\n",
            "          [1.9414e-01, 6.0876e-01],\n",
            "          ...,\n",
            "          [3.7756e-02, 6.5943e-01],\n",
            "          [8.2532e-01, 3.0392e-01],\n",
            "          [4.5035e-01, 4.6827e-01]],\n",
            "\n",
            "         [[5.4088e-01, 7.9916e-01],\n",
            "          [4.1888e-01, 2.9105e-01],\n",
            "          [4.0681e-01, 9.1934e-01],\n",
            "          ...,\n",
            "          [1.4710e-01, 4.2818e-02],\n",
            "          [1.5550e-01, 3.7162e-02],\n",
            "          [7.4583e-01, 1.5600e-01]],\n",
            "\n",
            "         [[7.2457e-01, 2.9045e-01],\n",
            "          [7.0591e-01, 1.6247e-01],\n",
            "          [9.8047e-01, 3.9457e-01],\n",
            "          ...,\n",
            "          [9.9956e-01, 8.5761e-01],\n",
            "          [1.4157e-01, 2.9618e-01],\n",
            "          [1.1376e-01, 3.4680e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[8.1761e-01, 3.1713e-01],\n",
            "          [4.2454e-01, 3.3251e-01],\n",
            "          [6.8902e-01, 9.8629e-01],\n",
            "          ...,\n",
            "          [8.4389e-01, 3.7049e-01],\n",
            "          [5.3387e-01, 7.0755e-01],\n",
            "          [6.8147e-01, 9.2747e-02]],\n",
            "\n",
            "         [[1.0061e-01, 8.5348e-02],\n",
            "          [4.4822e-02, 6.6880e-01],\n",
            "          [7.4338e-01, 4.7096e-01],\n",
            "          ...,\n",
            "          [3.2440e-01, 7.1014e-01],\n",
            "          [6.1452e-01, 5.9475e-01],\n",
            "          [8.5588e-02, 2.5979e-01]],\n",
            "\n",
            "         [[8.2181e-01, 9.3413e-01],\n",
            "          [5.1589e-01, 7.0402e-01],\n",
            "          [9.5872e-01, 7.4524e-01],\n",
            "          ...,\n",
            "          [2.6301e-01, 4.3852e-01],\n",
            "          [7.1664e-01, 8.8345e-01],\n",
            "          [3.2279e-02, 3.5565e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.4272e-01, 5.8151e-01],\n",
            "          [1.1822e-01, 2.7664e-01],\n",
            "          [1.9967e-01, 1.3987e-01],\n",
            "          ...,\n",
            "          [3.9850e-02, 7.0260e-01],\n",
            "          [1.5241e-01, 5.2620e-01],\n",
            "          [1.8549e-01, 3.7696e-01]],\n",
            "\n",
            "         [[3.7250e-01, 5.5241e-01],\n",
            "          [8.4031e-01, 2.4643e-01],\n",
            "          [3.8512e-01, 7.8290e-01],\n",
            "          ...,\n",
            "          [4.3630e-01, 7.9139e-01],\n",
            "          [6.6641e-01, 7.1520e-01],\n",
            "          [3.8312e-01, 8.5272e-01]],\n",
            "\n",
            "         [[8.4252e-01, 9.2336e-01],\n",
            "          [7.2097e-01, 4.8012e-01],\n",
            "          [8.9902e-02, 9.9753e-01],\n",
            "          ...,\n",
            "          [3.0198e-01, 1.9875e-01],\n",
            "          [4.3049e-01, 7.6402e-01],\n",
            "          [2.4262e-01, 5.4798e-01]]],\n",
            "\n",
            "\n",
            "        [[[1.1656e-01, 2.2187e-01],\n",
            "          [9.6186e-01, 5.6938e-01],\n",
            "          [5.1282e-02, 9.0705e-02],\n",
            "          ...,\n",
            "          [7.0574e-01, 5.4815e-01],\n",
            "          [2.9400e-01, 8.9519e-01],\n",
            "          [4.6089e-02, 9.2152e-01]],\n",
            "\n",
            "         [[7.1771e-01, 7.8037e-01],\n",
            "          [3.5962e-01, 3.7972e-01],\n",
            "          [5.8989e-01, 2.1997e-01],\n",
            "          ...,\n",
            "          [2.0975e-01, 5.4402e-01],\n",
            "          [2.6363e-01, 6.1664e-01],\n",
            "          [2.6424e-01, 1.6908e-01]],\n",
            "\n",
            "         [[1.9824e-02, 4.8372e-01],\n",
            "          [6.3163e-01, 2.1009e-01],\n",
            "          [7.3462e-01, 7.0486e-01],\n",
            "          ...,\n",
            "          [4.6335e-01, 5.4118e-02],\n",
            "          [7.3701e-01, 1.9062e-01],\n",
            "          [4.8483e-01, 6.2123e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[9.8718e-01, 6.8605e-01],\n",
            "          [1.6160e-01, 9.2752e-01],\n",
            "          [6.7915e-01, 4.3228e-01],\n",
            "          ...,\n",
            "          [3.2993e-01, 8.7239e-01],\n",
            "          [6.5771e-01, 4.8515e-01],\n",
            "          [3.5774e-01, 9.2780e-01]],\n",
            "\n",
            "         [[3.6163e-02, 8.1978e-01],\n",
            "          [1.9228e-01, 4.1891e-01],\n",
            "          [3.6704e-01, 6.5011e-04],\n",
            "          ...,\n",
            "          [8.9272e-02, 3.4737e-02],\n",
            "          [7.8237e-01, 5.9331e-01],\n",
            "          [9.9296e-02, 9.6090e-01]],\n",
            "\n",
            "         [[7.9934e-03, 7.3829e-01],\n",
            "          [8.8186e-01, 5.3987e-01],\n",
            "          [4.9156e-01, 3.4419e-01],\n",
            "          ...,\n",
            "          [5.1528e-01, 9.4856e-01],\n",
            "          [8.1334e-02, 8.7871e-01],\n",
            "          [5.5053e-02, 9.0190e-01]]],\n",
            "\n",
            "\n",
            "        [[[6.4771e-01, 8.8057e-02],\n",
            "          [2.3215e-02, 8.6902e-01],\n",
            "          [3.0080e-01, 5.3034e-02],\n",
            "          ...,\n",
            "          [2.5120e-01, 9.9495e-01],\n",
            "          [1.9761e-01, 1.5906e-02],\n",
            "          [7.8812e-01, 7.3004e-01]],\n",
            "\n",
            "         [[9.6830e-01, 7.5297e-01],\n",
            "          [5.1881e-01, 7.7226e-01],\n",
            "          [6.3669e-01, 5.9313e-01],\n",
            "          ...,\n",
            "          [3.0639e-01, 5.4502e-01],\n",
            "          [1.5331e-01, 4.7665e-01],\n",
            "          [3.7458e-01, 7.3785e-01]],\n",
            "\n",
            "         [[8.3635e-01, 3.6623e-01],\n",
            "          [3.6335e-01, 1.5355e-01],\n",
            "          [9.8245e-01, 2.4971e-01],\n",
            "          ...,\n",
            "          [8.2739e-01, 4.3016e-01],\n",
            "          [7.1347e-01, 7.6212e-01],\n",
            "          [9.2421e-01, 3.5921e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[8.8097e-01, 4.1188e-02],\n",
            "          [8.7933e-01, 8.7307e-01],\n",
            "          [6.9568e-01, 2.5851e-01],\n",
            "          ...,\n",
            "          [7.3728e-01, 9.0687e-01],\n",
            "          [2.2914e-01, 2.0669e-01],\n",
            "          [3.4309e-01, 4.2602e-01]],\n",
            "\n",
            "         [[5.3629e-01, 2.3412e-01],\n",
            "          [7.6830e-01, 9.6447e-01],\n",
            "          [5.2512e-01, 8.7329e-01],\n",
            "          ...,\n",
            "          [4.1715e-01, 5.0164e-02],\n",
            "          [7.6561e-01, 6.7669e-01],\n",
            "          [5.4390e-01, 2.3536e-01]],\n",
            "\n",
            "         [[2.2799e-01, 2.2263e-01],\n",
            "          [7.7124e-01, 2.3826e-01],\n",
            "          [8.4561e-01, 6.3545e-01],\n",
            "          ...,\n",
            "          [8.3584e-01, 7.5310e-01],\n",
            "          [6.9524e-01, 9.7205e-03],\n",
            "          [1.4159e-01, 1.9232e-02]]]])\n",
            "neighbours tensor([[[[6.7511e-01, 2.2035e-01],\n",
            "          [1.0373e-01, 7.1915e-01],\n",
            "          [7.3523e-01, 3.5263e-01],\n",
            "          ...,\n",
            "          [8.8915e-01, 3.5289e-01],\n",
            "          [8.6448e-01, 9.6081e-01],\n",
            "          [5.2614e-01, 9.8626e-01]],\n",
            "\n",
            "         [[9.3510e-01, 6.3995e-01],\n",
            "          [6.0520e-01, 1.8852e-01],\n",
            "          [5.3555e-01, 2.8827e-01],\n",
            "          ...,\n",
            "          [4.5520e-01, 7.8364e-01],\n",
            "          [7.1805e-01, 3.6377e-01],\n",
            "          [6.4626e-01, 3.2231e-01]],\n",
            "\n",
            "         [[1.5744e-01, 5.4404e-01],\n",
            "          [8.6668e-01, 4.3171e-01],\n",
            "          [1.6362e-02, 9.0749e-01],\n",
            "          ...,\n",
            "          [7.1788e-01, 5.9873e-01],\n",
            "          [9.7261e-02, 6.9230e-01],\n",
            "          [9.5213e-01, 5.5068e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[8.6849e-01, 6.1864e-01],\n",
            "          [9.6186e-01, 5.5125e-01],\n",
            "          [3.4290e-01, 8.8050e-01],\n",
            "          ...,\n",
            "          [8.3493e-01, 6.3308e-01],\n",
            "          [6.1546e-01, 8.6613e-01],\n",
            "          [2.5098e-01, 2.6704e-01]],\n",
            "\n",
            "         [[6.2757e-01, 3.4099e-01],\n",
            "          [4.2009e-01, 2.1378e-01],\n",
            "          [2.7606e-02, 3.7027e-01],\n",
            "          ...,\n",
            "          [4.6172e-01, 8.6905e-01],\n",
            "          [8.6444e-01, 8.5084e-01],\n",
            "          [7.0965e-01, 5.8757e-01]],\n",
            "\n",
            "         [[5.3359e-01, 8.5860e-01],\n",
            "          [5.8776e-01, 7.6678e-01],\n",
            "          [7.1128e-01, 6.1542e-01],\n",
            "          ...,\n",
            "          [9.1209e-01, 7.6784e-02],\n",
            "          [3.3194e-01, 7.7051e-01],\n",
            "          [4.7057e-01, 7.3307e-01]]],\n",
            "\n",
            "\n",
            "        [[[2.7884e-01, 8.5115e-01],\n",
            "          [5.7293e-01, 5.5282e-01],\n",
            "          [5.0851e-01, 8.9220e-01],\n",
            "          ...,\n",
            "          [9.3142e-01, 4.5666e-01],\n",
            "          [1.7710e-01, 6.2403e-01],\n",
            "          [9.8616e-01, 9.9172e-01]],\n",
            "\n",
            "         [[6.1955e-01, 6.8112e-01],\n",
            "          [9.9820e-01, 5.1917e-01],\n",
            "          [5.9446e-01, 6.2862e-01],\n",
            "          ...,\n",
            "          [3.2469e-01, 7.0245e-02],\n",
            "          [8.5711e-01, 6.1564e-01],\n",
            "          [1.8620e-01, 9.9272e-01]],\n",
            "\n",
            "         [[4.1991e-02, 6.8492e-01],\n",
            "          [8.2550e-01, 4.6816e-02],\n",
            "          [8.6447e-01, 9.4251e-01],\n",
            "          ...,\n",
            "          [8.8562e-01, 1.4946e-01],\n",
            "          [5.6794e-01, 3.8637e-01],\n",
            "          [7.0421e-01, 4.2418e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[9.4959e-02, 8.2721e-01],\n",
            "          [9.9970e-01, 1.1990e-01],\n",
            "          [2.0770e-01, 3.2142e-01],\n",
            "          ...,\n",
            "          [1.1127e-01, 9.0157e-01],\n",
            "          [1.4108e-01, 2.8919e-01],\n",
            "          [6.3362e-01, 4.5277e-01]],\n",
            "\n",
            "         [[4.2883e-01, 7.5964e-01],\n",
            "          [4.5235e-01, 9.5891e-01],\n",
            "          [6.1674e-01, 1.7779e-01],\n",
            "          ...,\n",
            "          [8.0245e-01, 5.3788e-01],\n",
            "          [4.1594e-01, 7.6685e-01],\n",
            "          [5.2643e-01, 9.1407e-01]],\n",
            "\n",
            "         [[9.9373e-01, 7.7570e-02],\n",
            "          [1.9828e-01, 6.2388e-01],\n",
            "          [4.8170e-01, 1.3595e-01],\n",
            "          ...,\n",
            "          [5.4638e-01, 7.9644e-01],\n",
            "          [4.6949e-02, 5.9080e-01],\n",
            "          [7.9348e-01, 3.3135e-01]]],\n",
            "\n",
            "\n",
            "        [[[8.7257e-01, 3.6302e-01],\n",
            "          [3.6270e-02, 5.9028e-02],\n",
            "          [6.3569e-01, 4.1028e-01],\n",
            "          ...,\n",
            "          [3.9011e-01, 6.8096e-02],\n",
            "          [2.3872e-01, 5.9808e-01],\n",
            "          [3.1571e-01, 9.0800e-01]],\n",
            "\n",
            "         [[5.4034e-01, 3.7519e-01],\n",
            "          [2.6635e-01, 3.1531e-01],\n",
            "          [2.7753e-01, 6.2192e-01],\n",
            "          ...,\n",
            "          [9.3347e-01, 9.5064e-01],\n",
            "          [2.8442e-01, 8.0937e-01],\n",
            "          [5.9176e-01, 2.3890e-01]],\n",
            "\n",
            "         [[8.6614e-01, 7.8818e-01],\n",
            "          [3.3435e-01, 3.6380e-01],\n",
            "          [9.7979e-01, 9.9973e-01],\n",
            "          ...,\n",
            "          [1.1973e-01, 1.7725e-01],\n",
            "          [9.7734e-01, 9.6490e-01],\n",
            "          [1.5749e-02, 9.4314e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[4.6602e-01, 1.8539e-01],\n",
            "          [8.3701e-01, 1.7999e-01],\n",
            "          [5.0247e-02, 3.2763e-01],\n",
            "          ...,\n",
            "          [7.0078e-01, 6.4140e-01],\n",
            "          [6.3443e-01, 4.2452e-01],\n",
            "          [2.5463e-01, 8.4741e-01]],\n",
            "\n",
            "         [[2.2264e-01, 3.5589e-01],\n",
            "          [3.9972e-01, 6.0690e-02],\n",
            "          [9.7132e-04, 2.5874e-01],\n",
            "          ...,\n",
            "          [5.7791e-01, 7.3422e-01],\n",
            "          [8.2408e-01, 7.9335e-02],\n",
            "          [5.8718e-01, 7.5686e-01]],\n",
            "\n",
            "         [[2.6133e-01, 9.5887e-01],\n",
            "          [2.0802e-01, 9.3187e-01],\n",
            "          [3.0893e-01, 9.1098e-01],\n",
            "          ...,\n",
            "          [1.9805e-02, 2.2864e-01],\n",
            "          [9.3929e-01, 4.6781e-01],\n",
            "          [7.1633e-01, 2.9285e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[1.4756e-01, 3.2728e-01],\n",
            "          [7.5288e-01, 2.2329e-01],\n",
            "          [6.2942e-01, 1.2126e-01],\n",
            "          ...,\n",
            "          [7.0527e-01, 5.7448e-01],\n",
            "          [5.8096e-01, 5.5919e-01],\n",
            "          [6.5703e-01, 5.4583e-01]],\n",
            "\n",
            "         [[4.4617e-02, 4.6009e-01],\n",
            "          [8.8379e-01, 9.3871e-01],\n",
            "          [3.8170e-01, 6.6203e-02],\n",
            "          ...,\n",
            "          [9.9052e-01, 1.0003e-01],\n",
            "          [3.3840e-01, 2.8110e-01],\n",
            "          [3.5727e-01, 1.5152e-01]],\n",
            "\n",
            "         [[7.1062e-01, 7.1569e-01],\n",
            "          [4.0423e-01, 6.0147e-01],\n",
            "          [3.6759e-01, 4.1576e-01],\n",
            "          ...,\n",
            "          [5.4827e-01, 8.6324e-01],\n",
            "          [8.7679e-01, 2.3581e-01],\n",
            "          [2.4948e-02, 5.9609e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[4.1111e-01, 5.7054e-02],\n",
            "          [3.1249e-01, 1.8538e-01],\n",
            "          [7.5061e-01, 9.7224e-01],\n",
            "          ...,\n",
            "          [2.4178e-01, 9.6309e-01],\n",
            "          [6.8463e-01, 9.6392e-01],\n",
            "          [2.1738e-01, 9.9402e-01]],\n",
            "\n",
            "         [[7.9754e-01, 4.2784e-01],\n",
            "          [2.1561e-01, 1.6607e-01],\n",
            "          [9.2235e-01, 1.3794e-01],\n",
            "          ...,\n",
            "          [4.3733e-01, 9.0426e-01],\n",
            "          [5.8868e-01, 9.5311e-01],\n",
            "          [4.6463e-01, 6.9816e-01]],\n",
            "\n",
            "         [[5.1137e-01, 9.0984e-01],\n",
            "          [3.5072e-02, 1.8418e-01],\n",
            "          [2.0272e-01, 8.5040e-01],\n",
            "          ...,\n",
            "          [8.4384e-02, 6.8746e-01],\n",
            "          [8.7295e-01, 8.0656e-01],\n",
            "          [3.5424e-01, 9.6254e-02]]],\n",
            "\n",
            "\n",
            "        [[[6.7549e-01, 4.9898e-01],\n",
            "          [3.3275e-01, 7.9274e-01],\n",
            "          [8.6869e-01, 4.4184e-01],\n",
            "          ...,\n",
            "          [8.6909e-01, 3.1859e-01],\n",
            "          [6.8638e-01, 3.5735e-01],\n",
            "          [9.3776e-04, 2.8160e-01]],\n",
            "\n",
            "         [[3.8980e-02, 3.0754e-01],\n",
            "          [1.4531e-01, 4.6636e-01],\n",
            "          [3.7136e-01, 9.3531e-01],\n",
            "          ...,\n",
            "          [3.8633e-01, 1.5884e-01],\n",
            "          [1.8424e-01, 8.9625e-01],\n",
            "          [8.6037e-01, 1.4999e-01]],\n",
            "\n",
            "         [[1.9429e-02, 2.6520e-01],\n",
            "          [5.0563e-01, 8.6066e-01],\n",
            "          [2.8434e-01, 5.7298e-02],\n",
            "          ...,\n",
            "          [5.0061e-01, 5.3712e-01],\n",
            "          [5.0976e-01, 9.4763e-01],\n",
            "          [4.8492e-01, 3.6280e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[4.7828e-01, 7.9000e-01],\n",
            "          [4.5013e-01, 1.9883e-01],\n",
            "          [8.3916e-01, 8.2807e-01],\n",
            "          ...,\n",
            "          [9.1097e-01, 1.9203e-01],\n",
            "          [5.4391e-01, 6.3073e-01],\n",
            "          [1.8107e-01, 6.1250e-01]],\n",
            "\n",
            "         [[4.4066e-01, 5.9227e-01],\n",
            "          [8.0728e-01, 5.7953e-02],\n",
            "          [1.5471e-01, 3.2762e-01],\n",
            "          ...,\n",
            "          [7.7798e-02, 8.3023e-01],\n",
            "          [2.4791e-01, 7.9560e-01],\n",
            "          [8.1193e-01, 3.2412e-01]],\n",
            "\n",
            "         [[8.3407e-01, 3.7489e-01],\n",
            "          [8.2269e-01, 5.7050e-01],\n",
            "          [6.8863e-02, 2.1409e-01],\n",
            "          ...,\n",
            "          [1.2529e-01, 8.6272e-01],\n",
            "          [9.5332e-01, 8.1911e-01],\n",
            "          [9.1805e-01, 8.7129e-01]]],\n",
            "\n",
            "\n",
            "        [[[7.7008e-01, 5.2741e-02],\n",
            "          [7.8363e-01, 1.4796e-01],\n",
            "          [9.2254e-01, 9.5678e-01],\n",
            "          ...,\n",
            "          [9.2118e-01, 7.5802e-01],\n",
            "          [7.6790e-01, 6.7771e-01],\n",
            "          [1.4421e-01, 8.4748e-01]],\n",
            "\n",
            "         [[7.2529e-01, 5.2823e-01],\n",
            "          [4.2319e-02, 9.3746e-01],\n",
            "          [2.2070e-01, 5.3086e-01],\n",
            "          ...,\n",
            "          [9.2858e-01, 6.1767e-01],\n",
            "          [9.5642e-01, 2.4626e-02],\n",
            "          [5.9876e-01, 8.1702e-01]],\n",
            "\n",
            "         [[5.4751e-01, 3.3828e-01],\n",
            "          [7.6607e-01, 4.7844e-01],\n",
            "          [5.4900e-01, 6.9907e-01],\n",
            "          ...,\n",
            "          [8.9293e-01, 1.9810e-01],\n",
            "          [7.1973e-01, 3.0012e-01],\n",
            "          [9.3672e-01, 7.1545e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.1864e-02, 6.6901e-01],\n",
            "          [3.4164e-01, 4.0122e-01],\n",
            "          [3.4177e-01, 4.4994e-01],\n",
            "          ...,\n",
            "          [8.6208e-01, 2.7736e-01],\n",
            "          [8.3924e-01, 1.0963e-01],\n",
            "          [3.3585e-01, 5.5769e-01]],\n",
            "\n",
            "         [[3.0900e-01, 2.8438e-01],\n",
            "          [5.0407e-01, 3.4647e-01],\n",
            "          [7.0245e-01, 6.9467e-01],\n",
            "          ...,\n",
            "          [4.3904e-01, 4.9966e-01],\n",
            "          [7.6987e-01, 2.9010e-02],\n",
            "          [5.5709e-03, 2.4855e-01]],\n",
            "\n",
            "         [[1.4387e-01, 6.7688e-01],\n",
            "          [6.2729e-01, 9.4084e-01],\n",
            "          [8.7286e-01, 6.2327e-01],\n",
            "          ...,\n",
            "          [9.1011e-01, 1.0675e-02],\n",
            "          [3.9999e-01, 2.1579e-01],\n",
            "          [3.3341e-01, 4.3277e-01]]]])\n",
            "goal tensor([[[0.9404, 0.1732],\n",
            "         [0.0972, 0.8602],\n",
            "         [0.8738, 0.2676],\n",
            "         ...,\n",
            "         [0.1472, 0.7927],\n",
            "         [0.0962, 0.7473],\n",
            "         [0.4976, 0.5080]],\n",
            "\n",
            "        [[0.5743, 0.5165],\n",
            "         [0.2983, 0.5480],\n",
            "         [0.0187, 0.7358],\n",
            "         ...,\n",
            "         [0.1685, 0.5326],\n",
            "         [0.4646, 0.6116],\n",
            "         [0.6058, 0.7102]],\n",
            "\n",
            "        [[0.4274, 0.3886],\n",
            "         [0.8314, 0.2207],\n",
            "         [0.3589, 0.8742],\n",
            "         ...,\n",
            "         [0.2747, 0.0994],\n",
            "         [0.1744, 0.6134],\n",
            "         [0.8192, 0.5266]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.2826, 0.2998],\n",
            "         [0.8503, 0.2555],\n",
            "         [0.7303, 0.4586],\n",
            "         ...,\n",
            "         [0.3111, 0.5810],\n",
            "         [0.3635, 0.4169],\n",
            "         [0.1481, 0.4837]],\n",
            "\n",
            "        [[0.6478, 0.4385],\n",
            "         [0.6005, 0.3486],\n",
            "         [0.5851, 0.5842],\n",
            "         ...,\n",
            "         [0.6257, 0.4245],\n",
            "         [0.1229, 0.8355],\n",
            "         [0.3762, 0.4918]],\n",
            "\n",
            "        [[0.2469, 0.6635],\n",
            "         [0.8810, 0.5191],\n",
            "         [0.5370, 0.3055],\n",
            "         ...,\n",
            "         [0.4996, 0.9931],\n",
            "         [0.2842, 0.0445],\n",
            "         [0.2384, 0.0279]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4068118038.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_goal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Output result shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2989467375.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, history, neighbors, goal)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mcurrent_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mpred_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_decoder_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mpred_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_callback_from_stance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m\"use_reentrant=False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         gen = _checkpoint_without_reentrant_generator(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2989467375.py\u001b[0m in \u001b[0;36mforward_decoder_step\u001b[0;34m(self, input_step, hx)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_decoder_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train_pfm_model(\n",
        "    data_path,\n",
        "    model_save_path,\n",
        "    model_class,\n",
        "    dataset_class,\n",
        "    collate_fn,\n",
        "    batch_size=32,\n",
        "    epochs=1,\n",
        "    learning_rate=0.001,\n",
        "    weight_decay=0.0,\n",
        "    device=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Train a PFM trajectory prediction model with speed constraints.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to dataset file.\n",
        "        model_save_path (str): Where to save the trained model.\n",
        "        model_class (class): Model class to instantiate (e.g., IntegratedMTAPFMModel).\n",
        "        dataset_class (class): Dataset loader class (e.g., PFM_TrajectoryDataset).\n",
        "        collate_fn (function): Collate function for DataLoader.\n",
        "        batch_size (int): Batch size for DataLoader.\n",
        "        epochs (int): Number of training epochs.\n",
        "        learning_rate (float): Learning rate for optimizer.\n",
        "        weight_decay (float): Weight decay for optimizer.\n",
        "        device (torch.device): Device to train on. If None, auto-select CUDA if available.\n",
        "    \"\"\"\n",
        "    device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    # === DATA LOADING ===\n",
        "    dataset = dataset_class(data_path)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # === MODEL / OPTIMIZER / LOSS ===\n",
        "    model = model_class().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    print(f\"\\n Speed Constraints Enabled:\")\n",
        "    print(f\"   Target Avg Speed: {model.target_avg_speed:.4f}\")\n",
        "    print(f\"   Allowed range: [{model.min_speed:.4f}, {model.max_speed:.4f}]\")\n",
        "    print(f\"   Tolerance: {model.speed_tolerance * 100:.1f}%\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        epoch_gt_speeds, epoch_pred_speeds, epoch_hist_speeds, epoch_violations = [], [], [], []\n",
        "\n",
        "        for batch_idx, (history, future, neighbors, goal) in enumerate(dataloader):\n",
        "            history = history.to(device)\n",
        "            future = future.to(device)\n",
        "            neighbors = neighbors.to(device)\n",
        "            goal = future[:, :, -1, :].clone()  # final target position\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred, coeff_mean, coeff_var = model(history, neighbors, goal)\n",
        "            loss = criterion(pred, future)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # === SPEED TRACKING ===\n",
        "            with torch.no_grad():\n",
        "                gt_speed = calculate_speed(future)\n",
        "                pred_speed = calculate_speed(pred)\n",
        "                hist_speed = calculate_speed(history)\n",
        "\n",
        "\n",
        "\n",
        "                epoch_gt_speeds.append(gt_speed.item())\n",
        "                epoch_pred_speeds.append(pred_speed.item())\n",
        "                epoch_hist_speeds.append(hist_speed.item())\n",
        "\n",
        "                violation_count = check_speed_violations(pred, history, model.min_speed, model.max_speed)\n",
        "                epoch_violations.append(violation_count)\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"[{batch_idx}] Loss: {loss:.4f} | k_att1 ={coeff_mean:.2f}, ={coeff_var:.2f}\")\n",
        "                print(f\"    Speeds - GT: {gt_speed:.3f}, Pred: {pred_speed:.3f}, Hist: {hist_speed:.3f}\")\n",
        "                print(f\"    Speed Violations: {violation_count}\")\n",
        "\n",
        "        # === EPOCH SUMMARY ===\n",
        "        avg_gt_speed = sum(epoch_gt_speeds) / len(epoch_gt_speeds)\n",
        "        avg_pred_speed = sum(epoch_pred_speeds) / len(epoch_pred_speeds)\n",
        "        avg_hist_speed = sum(epoch_hist_speeds) / len(epoch_hist_speeds)\n",
        "        total_violations = sum(epoch_violations)\n",
        "\n",
        "        print(f\"\\n=== EPOCH {epoch+1} SUMMARY ===\")\n",
        "        print(f\"Avg Loss: {epoch_loss/len(dataloader):.4f}\")\n",
        "        print(f\"Avg Speeds: Hist={avg_hist_speed:.4f}, GT={avg_gt_speed:.4f}, Pred={avg_pred_speed:.4f}\")\n",
        "        print(f\"Speed Error: {abs(avg_gt_speed - avg_pred_speed):.4f}\")\n",
        "        print(f\"Violations: {total_violations} | Constraint Compliance: {(1 - total_violations/(len(dataloader)*batch_size*5*12))*100:.2f}%\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        # === CLEAR CUDA CACHE AND COLLECT GARBAGE AFTER EACH EPOCH ===\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    # === SAVE MODEL ===\n",
        "    print(\"\\n Saving model...\")\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epochs,\n",
        "        'loss': epoch_loss/len(dataloader),\n",
        "        'speed_constraints': {\n",
        "            'target_avg_speed': model.target_avg_speed,\n",
        "            'min_speed': model.min_speed,\n",
        "            'max_speed': model.max_speed,\n",
        "            'tolerance': model.speed_tolerance\n",
        "        },\n",
        "        'final_avg_speeds': {\n",
        "            'historical': avg_hist_speed,\n",
        "            'ground_truth': avg_gt_speed,\n",
        "            'predicted': avg_pred_speed\n",
        "        }\n",
        "    }, model_save_path)\n",
        "    print(f\" Model saved at {model_save_path} with speed constraints!\")\n",
        "\n",
        "\n",
        "train_pfm_model(\n",
        "        data_path=\"/content/crowds_zara02_test_cleaned.txt\",\n",
        "        model_save_path=\"/content/mta_pfm_trajectory_model_zara.pth\",\n",
        "        model_class=CheckpointedIntegratedMTAPFMModel,\n",
        "        dataset_class=PFM_TrajectoryDataset,\n",
        "        collate_fn=collate_fn,\n",
        "        batch_size=32,\n",
        "        epochs=5\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dsuXQwn4z-S",
        "outputId": "5cb90539-e0b6-4010-83ae-e6cf18c1ec71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Speed Constraints Enabled:\n",
            "   Target Avg Speed: 0.0270\n",
            "   Allowed range: [0.0229, 0.0310]\n",
            "   Tolerance: 15.0%\n",
            "\n",
            "[0] Loss: 17.3595 | k_att1 =1.00, =0.00\n",
            "    Speeds - GT: 8.935, Pred: 0.030, Hist: 8.964\n",
            "    Speed Violations: 1605\n",
            "\n",
            "=== EPOCH 1 SUMMARY ===\n",
            "Avg Loss: 19.7292\n",
            "Avg Speeds: Hist=9.0538, GT=9.0336, Pred=0.0310\n",
            "Speed Error: 9.0026\n",
            "Violations: 59019 | Constraint Compliance: 6.85%\n",
            "========================================\n",
            "[0] Loss: 17.3800 | k_att1 =0.99, =0.00\n",
            "    Speeds - GT: 8.996, Pred: 0.031, Hist: 9.038\n",
            "    Speed Violations: 2049\n",
            "\n",
            "=== EPOCH 2 SUMMARY ===\n",
            "Avg Loss: 21.0473\n",
            "Avg Speeds: Hist=9.1360, GT=9.1171, Pred=0.0310\n",
            "Speed Error: 9.0861\n",
            "Violations: 58408 | Constraint Compliance: 7.82%\n",
            "========================================\n",
            "[0] Loss: 17.2901 | k_att1 =0.99, =0.00\n",
            "    Speeds - GT: 9.118, Pred: 0.031, Hist: 9.100\n",
            "    Speed Violations: 1966\n",
            "\n",
            "=== EPOCH 3 SUMMARY ===\n",
            "Avg Loss: 19.7568\n",
            "Avg Speeds: Hist=9.0571, GT=9.0336, Pred=0.0310\n",
            "Speed Error: 9.0026\n",
            "Violations: 60147 | Constraint Compliance: 5.07%\n",
            "========================================\n",
            "[0] Loss: 20.8516 | k_att1 =0.99, =0.00\n",
            "    Speeds - GT: 8.609, Pred: 0.031, Hist: 8.600\n",
            "    Speed Violations: 1990\n",
            "\n",
            "=== EPOCH 4 SUMMARY ===\n",
            "Avg Loss: 19.6691\n",
            "Avg Speeds: Hist=9.0383, GT=9.0226, Pred=0.0310\n",
            "Speed Error: 8.9915\n",
            "Violations: 61468 | Constraint Compliance: 2.99%\n",
            "========================================\n",
            "[0] Loss: 17.7078 | k_att1 =0.98, =0.00\n",
            "    Speeds - GT: 9.196, Pred: 0.031, Hist: 9.233\n",
            "    Speed Violations: 1804\n",
            "\n",
            "=== EPOCH 5 SUMMARY ===\n",
            "Avg Loss: 19.8078\n",
            "Avg Speeds: Hist=9.0422, GT=9.0273, Pred=0.0310\n",
            "Speed Error: 8.9962\n",
            "Violations: 61946 | Constraint Compliance: 2.23%\n",
            "========================================\n",
            "\n",
            " Saving model...\n",
            " Model saved at /content/mta_pfm_trajectory_model_zara.pth with speed constraints!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_with_metrics_mta_pfm(model_path, cleaned_txt_file):   #load different models accordingly\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    dataset = PFM_TrajectoryDataset(cleaned_txt_file)\n",
        "    print(f\"\\n Loaded {len(dataset)} frame samples for evaluation.\")\n",
        "\n",
        "    if len(dataset) == 0:\n",
        "        print(\" No valid samples available. Check your preprocessing.\")\n",
        "        return\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    model = CheckpointedIntegratedMTAPFMModel().to(device)\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    total_ade, total_fde, total_miss = 0.0, 0.0, 0.0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for history, future, neighbors, goal in dataloader:\n",
        "            history = history.to(device)\n",
        "            future = future.to(device)\n",
        "            neighbors = neighbors.to(device)\n",
        "            goal = goal.to(device)\n",
        "\n",
        "            pred, _, _ = model(history, neighbors, goal)  # [1, A, 12, 2]\n",
        "            pred = pred[0]    # [A, 12, 2]\n",
        "            future = future[0]  # [A, T, 2]\n",
        "\n",
        "            # Fix length mismatch\n",
        "            min_len = min(pred.size(1), future.size(1))\n",
        "            if pred.size(1) != future.size(1):\n",
        "                print(f\" Truncating: pred_len={pred.size(1)}, future_len={future.size(1)}  using {min_len}\")\n",
        "            pred = pred[:, :min_len, :]\n",
        "            future = future[:, :min_len, :]\n",
        "\n",
        "            ade = torch.norm(pred - future, dim=-1).mean().item()\n",
        "            fde = torch.norm(pred[:, -1, :] - future[:, -1, :], dim=-1).mean().item()\n",
        "            miss = (torch.norm(pred[:, -1, :] - future[:, -1, :], dim=-1) > 2.0).float().mean().item()\n",
        "\n",
        "            total_ade += ade\n",
        "            total_fde += fde\n",
        "            total_miss += miss\n",
        "            count += 1\n",
        "\n",
        "    if count == 0:\n",
        "        print(\" Evaluation aborted: No samples processed.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n Evaluation Metrics on Test Dataset:\")\n",
        "    print(f\" Average ADE:  {total_ade / count:.4f}\")\n",
        "    print(f\" Average FDE:  {total_fde / count:.4f}\")\n",
        "    print(f\" Miss Rate:    {total_miss / count:.4f} (threshold: 2m)\")"
      ],
      "metadata": {
        "id": "JdkOAD4Y7SnH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_with_metrics_mta_pfm(\n",
        "        '/content/mta_pfm_trajectory_model_zara.pth',\n",
        "        '/content/crowds_zara02_test_cleaned.txt'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HugU4-5a7SqJ",
        "outputId": "467898d2-497b-4fc2-8f48-954ca44cea13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loaded 1025 frame samples for evaluation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2431836939.py:124: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1839.)\n",
            "  coeff_var = coeff_stack.var(unbiased=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation Metrics on Test Dataset:\n",
            " Average ADE:  nan\n",
            " Average FDE:  nan\n",
            " Miss Rate:    nan (threshold: 2m)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DDDtvsV7Sto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XINtNhHb7Sx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}